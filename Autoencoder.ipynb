{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Autoencoder.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohitsurana3008/InterviewPractice/blob/Development/Autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pMEXiv8NC6Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwwJt8d4NPm6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_figure(image, number, fig, fig_dir):\n",
        "    \"\"\"Saves a figure to disk as png.\n",
        "    Arguments:\n",
        "    image -- A 2-D matrix of pixels, values from 0 to 1, black and white\n",
        "    number -- A number used for image title and filename\n",
        "    fig -- Initialized pyplot figure, we do not create a new one every time\n",
        "    fig_dir -- Directory in which to save figure\n",
        "    \"\"\"\n",
        "    plt.clf()\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image, cmap='gray')\n",
        "    plt.title('Step {}'.format(number))\n",
        "    save_path = os.path.join(fig_dir, 'fig_step_{:06d}'.format(number))\n",
        "    # Additional arguments used to get rid of unneeded boundaries in the image\n",
        "    fig.savefig(save_path, bbox_inches='tight', pad_inches=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHy8JjVcNljl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def autoencoder(x, output_size, outer_size=500, inner_size=1000,\n",
        "                name='autoencoder'):\n",
        "    \"\"\"Defines TensorFlow autoencoder model.\n",
        "    Arguments:\n",
        "    x -- Input tensor\n",
        "    output_size -- Output layer size (should be the same as input)\n",
        "    outer size -- Used for encoder and decoder layer sizes\n",
        "    inner_size -- Code (latent) layer size\n",
        "    Returns:\n",
        "    output -- Model outputs\n",
        "    \"\"\"\n",
        "    with tf.variable_scope(name):\n",
        "        encoder = tf.layers.dense(x, outer_size, name='encoder')\n",
        "        code = tf.layers.dense(encoder, inner_size, name='code')\n",
        "        decoder = tf.layers.dense(code, outer_size, name='decoder')\n",
        "        output = tf.layers.dense(decoder, output_size, name='output')\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_ppeKUMNu82",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main(unused_argv):\n",
        "    # Load MNIST data, NOTE: Deprecated and removed in TF 1.7\n",
        "    mnist = tf.contrib.learn.datasets.load_dataset('mnist')\n",
        "    # One example figure to reconstruct (for figures)\n",
        "    example_fig = [mnist.train.images[10]]\n",
        "    # Learning rate for Adam optimizer\n",
        "    learning_rate = 0.001\n",
        "    # Images are 28*28 pixels\n",
        "    input_size = 28*28\n",
        "    batch_size = 100\n",
        "    # Total number of steps\n",
        "    steps = 4000\n",
        "    # Save training loss and image every [save_every] steps\n",
        "    save_every = 100\n",
        "\n",
        "    # Create figure directory if doesn't exist\n",
        "    fig_dir = 'figures'\n",
        "    if not os.path.exists(fig_dir):\n",
        "        os.makedirs(fig_dir)\n",
        "    # Initialize pyplot figure, we only create one\n",
        "    fig = plt.figure(frameon=False)\n",
        "\n",
        "    # Input placeholder\n",
        "    x = tf.placeholder(tf.float32, [None, input_size], name='input')\n",
        "    output = autoencoder(x, input_size)\n",
        "    loss = tf.losses.mean_squared_error(x, output)\n",
        "    train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
        "\n",
        "    with tf.Session() as sess:\n",
        "        init = tf.global_variables_initializer()\n",
        "        sess.run(init)\n",
        "        # Writer for tensorboard\n",
        "        writer = tf.summary.FileWriter('logdir', sess.graph)\n",
        "        train_summary = tf.summary.scalar('train_loss', loss)\n",
        "\n",
        "        for i in range(1, steps+1):\n",
        "            # Take a new batch and train\n",
        "            batch, _ = mnist.train.next_batch(batch_size)\n",
        "            _, l, ts = sess.run([train_op, loss, train_summary],\n",
        "                                feed_dict={x: batch})\n",
        "\n",
        "            if i % save_every == 0:\n",
        "                print('Training loss at step {0}: {1}'.format(i, l))\n",
        "                writer.add_summary(ts, i)\n",
        "                # Reconstruct example image\n",
        "                result = sess.run([output], feed_dict={x: example_fig})\n",
        "                # Reshape flat vector into an array\n",
        "                reshaped = np.reshape(result, (28, 28))\n",
        "                save_figure(reshaped, i, fig, fig_dir)\n",
        "\n",
        "        # Use the whole test data for calculating final test loss\n",
        "        test_data = mnist.test.images\n",
        "        _, test_loss = sess.run([output, loss], feed_dict={x: test_data})\n",
        "        print('Final test loss: {}'.format(test_loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUp1VZ_LN5Hm",
        "colab_type": "code",
        "outputId": "8ffbcb22-53d7-4186-a6f4-fa525d95f902",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1175
        }
      },
      "source": [
        "\n",
        "if __name__ == '__main__':\n",
        "    tf.reset_default_graph()\n",
        "    tf.logging.set_verbosity(tf.logging.INFO)\n",
        "    tf.app.run(main=main)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n",
            "Training loss at step 100: 0.015257132239639759\n",
            "Training loss at step 200: 0.009969194419682026\n",
            "Training loss at step 300: 0.008086182177066803\n",
            "Training loss at step 400: 0.007097399793565273\n",
            "Training loss at step 500: 0.005686723627150059\n",
            "Training loss at step 600: 0.0065235113725066185\n",
            "Training loss at step 700: 0.005977568216621876\n",
            "Training loss at step 800: 0.006191653199493885\n",
            "Training loss at step 900: 0.006368593778461218\n",
            "Training loss at step 1000: 0.00633922778069973\n",
            "Training loss at step 1100: 0.006401579361408949\n",
            "Training loss at step 1200: 0.006648071575909853\n",
            "Training loss at step 1300: 0.006703199353069067\n",
            "Training loss at step 1400: 0.006107590161263943\n",
            "Training loss at step 1500: 0.006250586826354265\n",
            "Training loss at step 1600: 0.006481338758021593\n",
            "Training loss at step 1700: 0.005927455145865679\n",
            "Training loss at step 1800: 0.005977793596684933\n",
            "Training loss at step 1900: 0.006170804612338543\n",
            "Training loss at step 2000: 0.005988514516502619\n",
            "Training loss at step 2100: 0.006062506698071957\n",
            "Training loss at step 2200: 0.00607707817107439\n",
            "Training loss at step 2300: 0.006574353668838739\n",
            "Training loss at step 2400: 0.005807970184832811\n",
            "Training loss at step 2500: 0.006307731848210096\n",
            "Training loss at step 2600: 0.006255551241338253\n",
            "Training loss at step 2700: 0.0063352868892252445\n",
            "Training loss at step 2800: 0.006267115473747253\n",
            "Training loss at step 2900: 0.006125204730778933\n",
            "Training loss at step 3000: 0.006090730894356966\n",
            "Training loss at step 3100: 0.006256272550672293\n",
            "Training loss at step 3200: 0.006209435407072306\n",
            "Training loss at step 3300: 0.006185692735016346\n",
            "Training loss at step 3400: 0.0064248391427099705\n",
            "Training loss at step 3500: 0.0061264559626579285\n",
            "Training loss at step 3600: 0.005789584945887327\n",
            "Training loss at step 3700: 0.005969701334834099\n",
            "Training loss at step 3800: 0.0064400904811918736\n",
            "Training loss at step 3900: 0.006194018293172121\n",
            "Training loss at step 4000: 0.006530496291816235\n",
            "Final test loss: 0.005928536411374807\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noMRT7P8JvJ4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}